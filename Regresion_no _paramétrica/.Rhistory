ECM_lasso <- mean((ridge.pred - test_data$usa)^2)
print(ECM_lasso)
'Podemos observar que el modelo con LASSO tiene muchos más coeficientes que son cero'
library(glmnet)
# Cargar el dataframe desde un archivo CSV
df <- read.csv("rdpercentGDP.csv")
# Crear el gráfico
plot(df$year, df$argen, type = "l", ylim = c(0, 5), col = "green",
xlab = "Año", ylab = "Valores", main = "Comparación de Países a lo Largo de los Años")
# Lista de países y colores
countries <- c("argen", "germany", "france", "china", "japan", "usa", "uk", "nld", "finland")
colors <- c("green", "red", "purple", "blue", "orange", "darkgreen", "brown", "pink", "yellow")
names <- c("Argentina", "Alemania", "Francia", "China", "Japón", "USA", "Reino Unido", "Países Bajos", "Finland")
# Añadir las líneas de cada país y el texto correspondiente
for (i in seq_along(countries)) {
lines(df$year, df[[countries[i]]], col = colors[i])
text(df$year[length(df$year)], df[[countries[i]]][length(df[[countries[i]]])],
names[i], pos = 3, col = colors[i])
}
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(2024)
train_indices <- sample(seq_len(nrow(df)), size = 0.8 * nrow(df))
train_data <- df[train_indices, ]
test_data <- df[-train_indices, ]
# Verificar la división
print("Conjunto de entrenamiento:")
print(train_data)
print("Conjunto de prueba:")
print(test_data)
# Crear el modelo de regresión lineal
modelo <- lm(usa ~ germany + france + china + japan + uk + nld + finland, data = train_data)
summary(modelo)
# Calcular el error cuadrático medio en los datos de prueba
predicciones <- predict(modelo, newdata = test_data)
ECM <- mean((test_data$usa - predicciones)^2)
print(ECM)
# Analizar la correlación entre las variables
print(cor(train_data))
'RIDGE'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.ridge <- glmnet(matriz_diseño, train_data$usa, alpha = 0)
plot(ajuste.ridge)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 0, lambda = lambda_grid)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_ridge <- mean((ridge.pred - test_data$usa)^2)
print(ECM_ridge)
'LASSO'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.lasso <- glmnet(matriz_diseño, train_data$usa, alpha = 1)
plot(ajuste.lasso)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 1, lambda = lambda_grid)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_lasso <- mean((ridge.pred - test_data$usa)^2)
print(ECM_lasso)
'Podemos observar que el modelo con LASSO tiene muchos más coeficientes que son cero'
setwd("~/Estadística/Regresion_no _paramétrica")
library(glmnet)
# Cargar el dataframe desde un archivo CSV
df <- read.csv("rdpercentGDP.csv")
# Crear el gráfico
plot(df$year, df$argen, type = "l", ylim = c(0, 5), col = "green",
xlab = "Año", ylab = "Valores", main = "Comparación de Países a lo Largo de los Años")
# Lista de países y colores
countries <- c("argen", "germany", "france", "china", "japan", "usa", "uk", "nld", "finland")
colors <- c("green", "red", "purple", "blue", "orange", "darkgreen", "brown", "pink", "yellow")
names <- c("Argentina", "Alemania", "Francia", "China", "Japón", "USA", "Reino Unido", "Países Bajos", "Finland")
# Añadir las líneas de cada país y el texto correspondiente
for (i in seq_along(countries)) {
lines(df$year, df[[countries[i]]], col = colors[i])
text(df$year[length(df$year)], df[[countries[i]]][length(df[[countries[i]]])],
names[i], pos = 3, col = colors[i])
}
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(2024)
train_indices <- sample(seq_len(nrow(df)), size = 0.8 * nrow(df))
train_data <- df[train_indices, ]
test_data <- df[-train_indices, ]
# Verificar la división
print("Conjunto de entrenamiento:")
print(train_data)
print("Conjunto de prueba:")
print(test_data)
# Crear el modelo de regresión lineal
modelo <- lm(usa ~ germany + france + china + japan + uk + nld + finland, data = train_data)
summary(modelo)
# Calcular el error cuadrático medio en los datos de prueba
predicciones <- predict(modelo, newdata = test_data)
ECM <- mean((test_data$usa - predicciones)^2)
print(ECM)
# Analizar la correlación entre las variables
print(cor(train_data))
'RIDGE'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.ridge <- glmnet(matriz_diseño, train_data$usa, alpha = 0)
plot(ajuste.ridge)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 0, lambda = lambda_grid)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_ridge <- mean((ridge.pred - test_data$usa)^2)
print(ECM_ridge)
'LASSO'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.lasso <- glmnet(matriz_diseño, train_data$usa, alpha = 1)
plot(ajuste.lasso)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 1, lambda = lambda_grid)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_lasso <- mean((ridge.pred - test_data$usa)^2)
print(ECM_lasso)
'Podemos observar que el modelo con LASSO tiene muchos más coeficientes que son cero'
library(glmnet)
# Cargar el dataframe desde un archivo CSV
df <- read.csv("rdpercentGDP.csv")
# Crear el gráfico
plot(df$year, df$argen, type = "l", ylim = c(0, 5), col = "green",
xlab = "Año", ylab = "Valores", main = "Comparación de Países a lo Largo de los Años")
# Lista de países y colores
countries <- c("argen", "germany", "france", "china", "japan", "usa", "uk", "nld", "finland")
colors <- c("green", "red", "purple", "blue", "orange", "darkgreen", "brown", "pink", "yellow")
names <- c("Argentina", "Alemania", "Francia", "China", "Japón", "USA", "Reino Unido", "Países Bajos", "Finland")
# Añadir las líneas de cada país y el texto correspondiente
for (i in seq_along(countries)) {
lines(df$year, df[[countries[i]]], col = colors[i])
text(df$year[length(df$year)], df[[countries[i]]][length(df[[countries[i]]])],
names[i], pos = 3, col = colors[i])
}
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(2024)
train_indices <- sample(seq_len(nrow(df)), size = 0.8 * nrow(df))
train_data <- df[train_indices, ]
test_data <- df[-train_indices, ]
# Verificar la división
print("Conjunto de entrenamiento:")
print(train_data)
print("Conjunto de prueba:")
print(test_data)
# Crear el modelo de regresión lineal
modelo <- lm(usa ~ germany + france + china + japan + uk + nld + finland, data = train_data)
summary(modelo)
# Calcular el error cuadrático medio en los datos de prueba
predicciones <- predict(modelo, newdata = test_data)
ECM <- mean((test_data$usa - predicciones)^2)
print(ECM)
# Analizar la correlación entre las variables
print(cor(train_data[ , -c(1, 2, 8, 10)]))
'RIDGE'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.ridge <- glmnet(matriz_diseño, train_data$usa, alpha = 0)
plot(ajuste.ridge)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 0, lambda = lambda_grid)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_ridge <- mean((ridge.pred - test_data$usa)^2)
print(ECM_ridge)
'LASSO'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.lasso <- glmnet(matriz_diseño, train_data$usa, alpha = 1)
plot(ajuste.lasso)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 1, lambda = lambda_grid)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_lasso <- mean((ridge.pred - test_data$usa)^2)
print(ECM_lasso)
'Podemos observar que el modelo con LASSO tiene muchos más coeficientes que son cero'
'Conclusiones:
En principio, cuando hacemos el análisis Naive, podemos observar que los valores que arroja el modelo lineal sin penalización
son que Alemania, China, Japón, uk, y netherlands son los países que a nivel 0.05 tienen importancia. Ya con este ajuste,
tenemos un valor de R2 de 0.98, lo que nos dice que este modelo explica muy bien, aunque podríamos tener redundancias.
El ECM del modelo dio 0.004.
Cuando vemos la matriz de correlación, podemos '
# CONSIGNA----------------------------------------------------------------------
#Research and development expenditure (% of GDP)
#fuente data.worldbank.org
#https://data.worldbank.org/indicator/gb.xpd.rsdv.gd.zs?end=2016&start=1996&year_high_desc=false
# En economía, suelen aparecer variables explicativas muy correlacionadas.
# El gasto interno bruto en investigación  y desarrollo se define como el gasto total (corriente y capital) en I+D
# realizado por todas las empresas residentes en un país, sus institutos de investigación, laboratorios universitarios
# y gubernamentales, etc. Incluye la I+D financiada desde el extranjero, pero excluye los fondos nacionales para la I+D
# realizada fuera de la economía nacional. Este indicador se mide como porcentaje del PBI.
#
# En este contexto, se busca explicar el porcentaje de gasto en I+D de USA usando como covariables los porcentajes de gasto
# en I+D de otros países: Argentina, Alemania, China, Japón, Francia, Reino Unido y Finlandia, entre 1996 y 2016.
# 1) AED------------------------------------------------------------------------
# Datos
rdpercentGDP <- read.csv("rdpercentGDP.csv", row.names=1)
attach(rdpercentGDP)
#View(rdpercentGDP)
names(rdpercentGDP)
head(rdpercentGDP)
# Sacamos la columna de año y de nld, repetida
rdpercentGDP <- rdpercentGDP[,-c(1,9)]
# Gráficos
par(mfrow=c(1,1))
plot(1996:2016,france,type="l",col="blue",ylim=c(0,3.8),xlab="years",ylab="R&D (%GDP)",
main="Research and development expenditure (% of GDP)",lwd=2)
points(1996:2016,usa,type="l",lwd=2, col="black")
points(1996:2016,argen,type="l",col="lightblue",lwd=2)
points(1996:2016,germany,type="l",col="orange",lwd=2)
points(1996:2016,china,type="l",col="red",lwd=2)
points(1996:2016,japan,type="l",col="green",lwd=2)
points(1996:2016,finland,type="l",col="magenta",lwd=2)
points(1996:2016,uk,type="l",col="grey",lwd=2)
points(1996:2016,netherlands,type="l",col="darkred",lwd=2)
text(2015.2,france[21]+0.15,labels="France",col="blue")
text(2015.8,usa[21]-0.1,labels="USA",col="black")
text(2014.8,argen[21]+0.2,labels="Argentina",col="lightblue")
text(2015,germany[21]+0.1,labels="Germany",col="orange")
text(2015.2,china[21]+0.1,labels="China",col="red")
text(2015.2,japan[21]+0.3,labels="Japan",col="green")
text(2012,finland[17]+0.4,labels="Finland",col="magenta")
text(2015.5,uk[21]-0.2,labels="UK",col="grey")
text(2014.2,netherlands[21]-0.18,labels="Netherlands",col="darkred")
# 2)Train-test------------------------------------------------------------------
# Separamos los índices de entrenamiento y testeo
set.seed(1989)
train <- sample(c(TRUE,FALSE), nrow(rdpercentGDP), rep=TRUE, prob=c(0.8,0.2))
which(train==TRUE)
test <- !train
which(test==TRUE)
# 3)Ajuste lm-------------------------------------------------------------------
ajusteml<-lm(usa~.,data = rdpercentGDP[train,])
summary(ajusteml) # no dan significativas... pero la regresión globalmente sí
predichos <- predict(ajusteml, rdpercentGDP[test,])
ECM_est <- mean((predichos-rdpercentGDP[test,6])^2)
# 4)¿Correlación, multicolinealidad?--------------------------------------------
# Pequeña simulación
# Y = beta0 + beta1*X1 + beta2*X2 + beta3*X3 + eps, beta1 = 5beta2
set.seed(1989)
n <- 20
eps <- rnorm(n)
beta1 <- 10
beta2 <- 5*beta1
beta3 <- -1
x1 <- runif(n,200,300)
x2 <- runif(n,0,1)
x3 <- runif(n,-2,-1)
y <- beta1*x1+beta2*x2+beta3*x3+eps
datos <- data.frame(
x1 = x1,
x2 = x2,
x3 = x3,
y = y
)
summary(lm(y~.,data = datos))
# (Intercept) -0.279788   2.782721   -0.101    0.921
# x1          10.000852   0.009389 1065.140   <2e-16 ***
# x2          50.768809   1.312046   38.694   <2e-16 ***
# x3          -0.847241   1.169578   -0.724    0.479
summary(lm(y~.,data = datos[,-2]))
# (Intercept) -51.20782   23.13205  -2.214  0.04081 *
# x1           10.13074    0.08273 122.454  < 2e-16 ***
# x3          -28.06546    8.81594  -3.183  0.00544 **
summary(lm(y~.,data = datos[,-1]))
# (Intercept)   2549.5      366.5   6.956 2.32e-06 ***
# x2             550.4      316.5   1.739     0.10
# x3             182.2      298.9   0.610     0.55
# En nuestros datos, veamos que cambiando la semilla, cambian mucho las estimaciones
for(i in 1:5){
set.seed(1989+i)
train <- sample(c(TRUE,FALSE), nrow(rdpercentGDP), rep=TRUE, prob=c(0.8,0.2))
ajusteml<-lm(usa~.,data = rdpercentGDP[train,])
print(summary(ajusteml))
}
# ¿Será que estan muy correlacionadas?
pairs(rdpercentGDP)
library(ggplot2)
library(GGally)
ggpairs(rdpercentGDP)
library(corrplot)
library(glmnet)
# Cargar el dataframe desde un archivo CSV
df <- read.csv("rdpercentGDP.csv")
# Crear el gráfico
plot(df$year, df$argen, type = "l", ylim = c(0, 5), col = "green",
xlab = "Año", ylab = "Valores", main = "Comparación de Países a lo Largo de los Años")
# Lista de países y colores
countries <- c("argen", "germany", "france", "china", "japan", "usa", "uk", "nld", "finland")
colors <- c("green", "red", "purple", "blue", "orange", "darkgreen", "brown", "pink", "yellow")
names <- c("Argentina", "Alemania", "Francia", "China", "Japón", "USA", "Reino Unido", "Países Bajos", "Finland")
# Añadir las líneas de cada país y el texto correspondiente
for (i in seq_along(countries)) {
lines(df$year, df[[countries[i]]], col = colors[i])
text(df$year[length(df$year)], df[[countries[i]]][length(df[[countries[i]]])],
names[i], pos = 3, col = colors[i])
}
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(2024)
train_indices <- sample(seq_len(nrow(df)), size = 0.8 * nrow(df))
train_data <- df[train_indices, ]
test_data <- df[-train_indices, ]
# Verificar la división
print("Conjunto de entrenamiento:")
print(train_data)
print("Conjunto de prueba:")
print(test_data)
# Crear el modelo de regresión lineal
modelo <- lm(usa ~ germany + france + china + japan + uk + nld + finland, data = train_data)
summary(modelo)
# Calcular el error cuadrático medio en los datos de prueba
predicciones <- predict(modelo, newdata = test_data)
ECM <- mean((test_data$usa - predicciones)^2)
print(ECM)
# Analizar la correlación entre las variables
print(cor(train_data[ , -c(1, 2, 8, 10)]))
'RIDGE'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.ridge <- glmnet(matriz_diseño, train_data$usa, alpha = 0)
plot(ajuste.ridge)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 0, lambda = lambda_grid)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_ridge <- mean((ridge.pred - test_data$usa)^2)
print(ECM_ridge)
'LASSO'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.lasso <- glmnet(matriz_diseño, train_data$usa, alpha = 1)
plot(ajuste.lasso)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 1, lambda = lambda_grid)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_lasso <- mean((ridge.pred - test_data$usa)^2)
print(ECM_lasso)
'Podemos observar que el modelo con LASSO tiene muchos más coeficientes que son cero'
'Conclusiones:
En principio, cuando hacemos el análisis Naive, podemos observar que los valores que arroja el modelo lineal sin penalización
son que Alemania, China, Japón, uk, y netherlands son los países que a nivel 0.05 tienen importancia. Ya con este ajuste,
tenemos un valor de R2 de 0.98, lo que nos dice que este modelo explica muy bien, aunque podríamos tener redundancias.
El ECM del modelo dio 0.004.
Cuando vemos la matriz de correlación, podemos ver que la correlación entre Alemania y China es cercana a 0.98. Esto podría
significar que la independencia entre ambas variables es débil (tienen una relación casi lineal), por lo que quizás cuando
tengamos un modelo que penalice tenermuchos parámetros, tal vez elimine a una de las dos (o podríamos elegir al azar a mano).
Con regresión de Ridge, observamos que la mayoría de los coeficientes no son cero'
library(glmnet)
# Cargar el dataframe desde un archivo CSV
df <- read.csv("rdpercentGDP.csv")
# Crear el gráfico
plot(df$year, df$argen, type = "l", ylim = c(0, 5), col = "green",
xlab = "Año", ylab = "Valores", main = "Comparación de Países a lo Largo de los Años")
# Lista de países y colores
countries <- c("argen", "germany", "france", "china", "japan", "usa", "uk", "nld", "finland")
colors <- c("green", "red", "purple", "blue", "orange", "darkgreen", "brown", "pink", "yellow")
names <- c("Argentina", "Alemania", "Francia", "China", "Japón", "USA", "Reino Unido", "Países Bajos", "Finland")
# Añadir las líneas de cada país y el texto correspondiente
for (i in seq_along(countries)) {
lines(df$year, df[[countries[i]]], col = colors[i])
text(df$year[length(df$year)], df[[countries[i]]][length(df[[countries[i]]])],
names[i], pos = 3, col = colors[i])
}
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(2024)
train_indices <- sample(seq_len(nrow(df)), size = 0.8 * nrow(df))
train_data <- df[train_indices, ]
test_data <- df[-train_indices, ]
# Verificar la división
print("Conjunto de entrenamiento:")
print(train_data)
print("Conjunto de prueba:")
print(test_data)
# Crear el modelo de regresión lineal
modelo <- lm(usa ~ germany + france + china + japan + uk + nld + finland, data = train_data)
summary(modelo)
# Calcular el error cuadrático medio en los datos de prueba
predicciones <- predict(modelo, newdata = test_data)
ECM <- mean((test_data$usa - predicciones)^2)
print(ECM)
# Analizar la correlación entre las variables
print(cor(train_data[ , -c(1, 2, 8, 10)]))
'RIDGE'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.ridge <- glmnet(matriz_diseño, train_data$usa, alpha = 0)
plot(ajuste.ridge)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 0, lambda = lambda_grid, nfolds = 3)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
ridge.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_ridge <- mean((ridge.pred - test_data$usa)^2)
print(ECM_ridge)
# Criterio de 1SE
lambda_1se <- cv.out$lambda.1se
print(log(lambda_1se))
# Coeficientes del modelo con el lambda de 1SE
print(coef(cv.out, s = lambda_1se))
# Predicciones en el conjunto de prueba y cálculo del ECM con lambda de 1SE
ridge.pred_1se <- predict(cv.out, s = lambda_1se, newx = matriz_diseño_test)
ECM_ridge_1se <- mean((ridge.pred_1se - test_data$usa)^2)
print(ECM_ridge_1se)
'LASSO'
matriz_diseño <- as.matrix(train_data[ , -c(1, 2, 8, 10)])
ajuste.lasso <- glmnet(matriz_diseño, train_data$usa, alpha = 1)
plot(ajuste.lasso)
# RIDGE con CV
lambda_grid <- 10^seq(-4, 4, length = 100)
cv.out <- cv.glmnet(matriz_diseño, train_data$usa, alpha = 1, lambda = lambda_grid, nfolds = 3)
plot(cv.out)
bestlam <- cv.out$lambda.min
print(log(bestlam))
print(bestlam)
# Coeficientes del modelo con el mejor lambda
print(coef(cv.out, s = bestlam))
# Predicciones en el conjunto de prueba y cálculo del ECM
matriz_diseño_test <- as.matrix(test_data[ , -c(1, 2, 8, 10)])
lasso.pred <- predict(cv.out, s = bestlam, newx = matriz_diseño_test)
ECM_lasso <- mean((lasso.pred - test_data$usa)^2)
print(ECM_lasso)
# Criterio de 1SE
lambda_1se <- cv.out$lambda.1se
print(log(lambda_1se))
# Coeficientes del modelo con el lambda de 1SE
print(coef(cv.out, s = lambda_1se))
# Predicciones en el conjunto de prueba y cálculo del ECM con lambda de 1SE
lasso.pred_1se <- predict(cv.out, s = lambda_1se, newx = matriz_diseño_test)
ECM_lasso_1se <- mean((lasso.pred_1se - test_data$usa)^2)
print(ECM_lasso_1se)
'Podemos observar que el modelo con LASSO tiene muchos más coeficientes que son cero'
'Conclusiones:
En principio, cuando hacemos el análisis Naive, podemos observar que los valores que arroja el modelo lineal sin penalización
son que Alemania, China, Japón, uk, y netherlands son los países que a nivel 0.05 tienen importancia. Ya con este ajuste,
tenemos un valor de R2 de 0.98, lo que nos dice que este modelo explica muy bien, aunque podríamos tener redundancias.
El ECM del modelo dio 0.004.
Cuando vemos la matriz de correlación, podemos ver que la correlación entre Alemania y China es cercana a 0.98. Esto podría
significar que la independencia entre ambas variables es débil (tienen una relación casi lineal), por lo que quizás cuando
tengamos un modelo que penalice tenermuchos parámetros, tal vez elimine a una de las dos (o podríamos elegir al azar a mano).
Con regresión de Ridge, observamos que la mayoría de los coeficientes no son cero (usa todos los parámetros en el mdoelo).
El lambda que elige es 0.00021 y el ECM es 0.00338.
Con penalización LASSO, a partir de log(lambda)>2, empezamos a tener 0 coeficientes. Por lo que elige bestlam = 0.00053,
donde se queda con 7 coeficientes de 9 y el ECM es 0.02, que es menor que el anterior, por lo que podríamos quedarnos con
este en lugar del anterior en este punto.
Ahora, podríamos usar el criterio que marcó Ana de usar el error stándar para tomar una decisión:'
print(ECM_ridge_1se)
print(ECM_lasso_1se)
