---
title: "La_Dibunetta"
author: "Jalil_Pañale_Yudcovsky"
date: "2024-07-06"
output: pdf_document
---
PUNTO A
```{r}
setwd("~/Estadística/TP_final")
library(ggplot2)
datos <- read.csv("individuals.csv", sep = ";")
mujeres <- subset(datos, SEX == 2)
mujeres <- subset(mujeres, HIP.CIRCUMFERENCE != 0 & BUTTOCK.KNEE.LENGTH != 0)
plot(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH, main = "Diagrama de dispersión de \n Circunferencia de la cadera vs longitud del fémur",
     xlab = "Circunferencia de la cadera (mm)", ylab = "Longitud del fémur (mm)", col = "purple")
```
Podemos observar una clara relación creciente entre las variables. No hay outliers y los datos parecen bien cargados.
\n \n
PUNTO B
```{r}
mujeres_ordenado <- mujeres[order(mujeres$AGE.IN.MONTHS), ]
grupo_etario_1  <- mujeres_ordenado[1:466, ]
grupo_etario_2 <-  mujeres_ordenado[467:932, ]
grupo_etario_3 <-  mujeres_ordenado[933:1399, ]
grupo_etario_4<-  mujeres_ordenado[1400:1866, ]
grupos <- list(grupo_etario_1, grupo_etario_2, grupo_etario_3, grupo_etario_4)
medianas <- numeric(length(grupos))
for (i in 1:length(grupos)) {
  medianas[i] <- median(grupos[[i]]$HIP.CIRCUMFERENCE)
}
for (i in 1:4) {
  cat("Mediana grupo", i, ":" ,medianas[i], "\n")
}
```
Tenemos 1866 datos y lo dividimos en 4 partes iguales. Podmeos observar que los grupos están en orden creciente de edad, y las medianas que obtuvimos también fueron valores crecientes (mientras más edad, más hip circumference.)
```{r}
estimar_se_mediana <- function(datos, B = 1000) {
  theta_boot <- numeric(B)
  for (i in 1:B) {
    n <- length(datos)
    datos_boot <- sample(datos, n, replace = TRUE)
    theta_boot[i] <- median(datos_boot)
  }
  se_boot <- sqrt(mean((theta_boot - mean(theta_boot))^2))  # Desviación estándar de las medianas bootstrap
  return(se_boot)
}
intervalos_bootstrap <- list()
for (i in (1:4)){
  se_boot <- estimar_se_mediana(grupos[[i]]$HIP.CIRCUMFERENCE)
  intervalo_boot <- c(medianas[i] - 1.96 * se_boot , medianas[i] + 1.96 * se_boot)
  intervalos_bootstrap[[i]] <- intervalo_boot
}
for (i in 1:4) {
  cat("Intervalo de confianza bootstrap para grupo", i, ": [", round(intervalos_bootstrap[[i]][1], 2), ", ", round(intervalos_bootstrap[[i]][2], 2), "]\n")
}
```
```{r}

estadisticas <- data.frame(
  Grupo = c("Grupo 1", "Grupo 2", "Grupo 3", "Grupo 4"),
  Mediana = medianas,
  IC_lower = sapply(intervalos_bootstrap, `[`, 1),
  IC_upper = sapply(intervalos_bootstrap, `[`, 2)
)

estadisticas$label_pos <- estadisticas$IC_upper + 10  # Posición de la etiqueta para las barras de error
ggplot() +
  geom_point(data = grupo_etario_1, aes(x = HIP.CIRCUMFERENCE, y = rep("Grupo 1", nrow(grupo_etario_1))), color = "gray", size = 2, alpha = 0.5) +
  geom_point(data = grupo_etario_2, aes(x = HIP.CIRCUMFERENCE, y = rep("Grupo 2", nrow(grupo_etario_2))), color = "gray", size = 2, alpha = 0.5) +
  geom_point(data = grupo_etario_3, aes(x = HIP.CIRCUMFERENCE, y = rep("Grupo 3", nrow(grupo_etario_3))), color = "gray", size = 2, alpha = 0.5) +
  geom_point(data = grupo_etario_4, aes(x = HIP.CIRCUMFERENCE, y = rep("Grupo 4", nrow(grupo_etario_4))), color = "gray", size = 2, alpha = 0.5) +
  geom_point(data = estadisticas, aes(x = Mediana, y = Grupo), color = "darkorange", size = 2) +
  geom_errorbarh(data = estadisticas, aes(xmin = IC_lower, xmax = IC_upper, y = Grupo), height = 0.4, color = "darkblue", lwd = 1) +
  labs(title = "Datos de circunferencia de cadera con mediana e intervalo de confianza por grupo etario",
       x = "Circunferencia de la cadera (mm)",
       y = "Grupo etario") +
  theme_minimal()
```
//EXPLICACIÓN DE CÓMO PENSAMOS LA FUNCIÓN DEL INTERVALO (EXPLICACIÓN TEO 12)


c) i)
```{r}
ajuste_bw_100 <- ksmooth(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH, kernel = "normal", bandwidth = 100)
ajuste_bw_50 <- ksmooth(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH, kernel = "normal", bandwidth = 50)
plot(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH, 
     main = "Diagrama de dispersión de \n Circunferencia de la cadera vs longitud del fémur",
     xlab = "Circunferencia de la cadera (mm)", 
     ylab = "Longitud del fémur (mm)", 
     col = "purple")
lines(ajuste_bw_100$x, ajuste_bw_100$y, col = "blue", lwd = 2)
lines(ajuste_bw_50$x, ajuste_bw_50$y, col = "red", lwd = 2)
legend("topleft",legend = c("Bw = 100","Bw= 50"), col = c("blue","red"),lwd = 2)
```

¿Que sugiere el grafico obtenido? ¿Cual de las dos ventanas usarıa?

El grafico obtenido sugiere que ambos ajustes parecen seguir bastante bien a los datos relacionados. 
Siempre las ventanas mas chicas , en los sectores donde hay menor cantidad de datos, son mas sesgados por los datos , por lo que se pegan a cada punto , en cambio las ventanas mas grandes no siguen con esta dinamica, Por lo que podemos observar que en los extremos , la linea de Bw = 50 se ajusta mejor a los datos ya que en estas zonas escasean . 

Usariamos la ventana de 50 porque se ajusta mejor a los datos en las colas. Mientra que en el centro ambas se comportan casi de la misma manera.XD


ii)

```{r}
y = mujeres$BUTTOCK.KNEE.LENGTH
x = mujeres$HIP.CIRCUMFERENCE
ventanas <- seq(20, 50, by = 1)
cv_errors <- rep(0, length(ventanas))
for (j in seq_along(ventanas)) {
  h <- ventanas[j]
  cv_error <- 0
  for (i in 1:length(y)) {
    xi <- x[-i]
    yi <- y[-i]
    m_estimado <- ksmooth(xi, yi, kernel = "normal", bandwidth = h, x.points = x[i])
    cv_error <- cv_error + (y[i] - m_estimado$y)^2
    cv_errors[j] <- cv_error/length(y)
    }
  cv_errors[j] <- cv_error/length(y)
}
h_optimo <- ventanas[which.min(cv_errors)]
print(h_optimo)
```
iii)

```{r}
#parte de cross validation
nwsmooth<- function(h, x, y) {
  cv <- rep(0, length(y))
  for (i in 1:length(y)) {
    xi <- x[-i]
    yi <- y[-i]
    m_estimado <- ksmooth(xi, yi, kernel = "normal", bandwidth = h, x.points = x[i])
    cv[i] <- (y[i] - m_estimado$y)^2
  }
  return(mean(cv))
}
h_optimos <- seq(20, 50, by = 1)
valores_del_error_h_optimo <- sapply(h_optimos, nwsmooth, x = mujeres$HIP.CIRCUMFERENCE, y = mujeres$BUTTOCK.KNEE.LENGTH)
h_optimo <- h_optimos[which.min(valores_del_error_h_optimo)]
plot(h_optimos, valores_del_error_h_optimo, type = "l", col = "blue", lwd = 2,
     xlab = "h (Ancho de banda)", 
     ylab = "CV(h)", 
     main = "Validación cruzada para seleccionar h óptimo")
abline(v = h_optimo, col = "red", lty = 2)
paste("La ventana óptima es:", h_optimo)
```
Podemos asumir que la función de las ventanas que graficamos es unimodal bajo alguna condición de regularidad, por lo que si queremos encontrar un h mínimo en cierta grilla, si nos da o bien el valor más chico o bien el valor más grande, podría pasar que el óptimo esté por fuera de la grilla, pero al estar el óptimo al medio de la grilla, por def va a ser óptimo global, por lo que no tenemos que extender la grilla pues no estamos perdiendo ningún valor de h menor.


iv)

Primero realizamos el modelo con todos los datos , sin separar en conjunto de entrenamiento y conjunto de prueba . 

```{r}
ajuste_bw_optimo <- ksmooth(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH, kernel = "normal", bandwidth = h_optimo)
ajuste_lm <- lm(BUTTOCK.KNEE.LENGTH ~ HIP.CIRCUMFERENCE, data = mujeres)
plot(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH,
     main = "Diagrama de dispersión de \n Circunferencia de la cadera vs longitud del fémur",
     xlab = "Circunferencia de la cadera (mm)", 
     ylab = "Longitud del fémur (mm)", 
     col = "purple")
lines(ajuste_bw_optimo$x, ajuste_bw_optimo$y, col = "blue", lwd = 2)
abline(ajuste_lm, col = "green", lwd = 2)
legend("bottomright",legend = c("Curva con Ventana optima","Curva de minimos cuadrados"), col = c("blue","green"),lwd = 2)
```
Claramente nos quedamos con la curva de nwsmooth ya que se puede observar que aproxima mucho mejor los datos . 

Ahora dividimos los datos en dos conjuntos: uno para entrenar el modelo (conjunto de entrenamiento) y otro para evaluar su rendimiento (conjunto de prueba).

```{r}
train_indices <- sample(seq_len(nrow(mujeres)), size = 0.8 * nrow(mujeres))
train_data <- mujeres[train_indices, ]
test_data <- mujeres[-train_indices, ]
```


Ahora creamos el modelo de regresión lineal y calculamos el error cuadrático medio en los datos de prueba .

```{r}
ajuste_bw_optimo <- ksmooth(train_data$HIP.CIRCUMFERENCE, train_data$BUTTOCK.KNEE.LENGTH, kernel = "normal", bandwidth = h_optimo)
modelo <- lm( BUTTOCK.KNEE.LENGTH ~ HIP.CIRCUMFERENCE, data = train_data)
predicciones <- predict(modelo, newdata = test_data)
plot(test_data$HIP.CIRCUMFERENCE, test_data$BUTTOCK.KNEE.LENGTH,
     main = "Diagrama de dispersión de \n Circunferencia de la cadera vs longitud del fémur",
     xlab = "Circunferencia de la cadera (mm)", 
     ylab = "Longitud del fémur (mm)", 
     col = "purple")
lines(ajuste_bw_optimo$x, ajuste_bw_optimo$y, col = "blue", lwd = 2)
abline(modelo, col = "green", lwd = 2)
legend("bottomright",legend = c("Curva con Ventana optima","Curva de minimos cuadrados"), col = c("blue","green"),lwd = 2)
```
DAFNE ES UNA TROLA 

PUNTO D 

Esta función calculará el estimador lineal local utilizando el método de mínimos cuadrados ponderados por un núcleo normal.
Utilizaremos la fórmula matricial mencionada en el texto para encontrar el intercepto y  la pendient,  que minimizan la suma ponderada de los residuos cuadrados.

En el contexto de la regresión local (como Nadaraya-Watson o regresión local lineal), se utilizan pesos basados en un núcleo (kernel) que asigna mayor peso a las observaciones cercanas al punto donde se realiza la estimación y menor peso a las observaciones más lejanas. Esto ayuda a que las observaciones más cercanas tengan una influencia mayor en la estimación local.

```{r}
# Definir la función linearsmooth
linearsmooth <- function(x, y, h, x0) {
  n <- length(x)
  K <- dnorm((x0 - x) / h)  # Kernel normal en el punto x0
  X <- cbind(1, x)
  weights <- diag(K)
  coef <- solve(t(X) %*% weights %*% X) %*% t(X) %*% weights %*% y
  return(coef)
}

# Coeficientes del estimador lineal local en el punto promedio de HIP.CIRCUMFERENCE
x0 <- mean(mujeres$HIP.CIRCUMFERENCE)
coeficientes <- linearsmooth(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH, 40, x0)
ordenada <- coeficientes[1]
pendiente <- coeficientes[2]

# Graficar
plot(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH,
     main = "Diagrama de dispersión de \n Circunferencia de la cadera vs longitud del fémur",
     xlab = "Circunferencia de la cadera (mm)", 
     ylab = "Longitud del fémur (mm)", 
     col = "purple")
abline(ordenada, pendiente, col = "darkgreen", lwd = 2)

# Ajuste usando h óptimo
ajuste_bw_optimo <- ksmooth(mujeres$HIP.CIRCUMFERENCE, mujeres$BUTTOCK.KNEE.LENGTH, kernel = "normal", bandwidth = h_optimo)

# Graficar el ajuste de Nadaraya-Watson
lines(ajuste_bw_optimo$x, ajuste_bw_optimo$y, col = "darkorange", lwd = 2)
legend("bottomright", legend = c("Estimador linealizado", "Nadayara-Watson"), col = c("darkgreen", "darkorange"), lwd = 2)

```








