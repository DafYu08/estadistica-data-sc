est1 <- c(est1, t1)
t2 <- sd(muestra_exp)^2
est2 <- c(est2, t2)
error1 <- error1 + error_cuadratico_medio(t1)
error2 <- error2 + error_cuadratico_medio(t2)
}
#Ejercicio c
#Armo boxplots paralelos
par(mfrow=c(1,2))
boxplot(est1, col="blue", main = "Primer estimador")
boxplot(est2, col = "green", main = "Segundo estimador")
#Ejercicio d
#Funciones para elegir ventana
nucleo_gaussiano <- function(u){
kernel <- exp(-(u^2)/2)/sqrt(2*pi)
return(kernel)
}
f_sombrero <- function(muestra, kernel, datos, h){
suma <- 0
for(i in 1:length(datos)){
actual <- kernel((muestra-datos[i])/h)
suma <- suma + actual
}
f <- suma / (length(datos) * h)
return(f)
}
'
# Ventana de Silverman (al final no lo usé porque son exponenciales)
h_Silverman <- 1.06 * min(sd(muestras), IQR(muestras) / 1.349) * length(muestras) ^ (-1/5)
# Venta usando Convalidación Cruzada
elegir_ventana_CV <- function(muestras){
h <- c(8, 10, 0.001)
vector_1 <- c()
for(j in 1:length(h)){
vector_2 <- c()
for(i in 1:length(muestras)){
f_actual <- f_sombrero(muestras[i], nucleo_gaussiano, muestras[-i], h[j])
vector_2[i] <- log(f_actual)
}
vector_1[j] <- mean(na.omit(vector_2))
}
h_CV <- h[which.max(vector_1)]
return(h_CV)
}
'
par(mfrow=c(1,1))
# Utilizando la ventana estimada_2 para las densidades 1 y 2
densidad_t1 <- density(est1, kernel = "gauss")# window = bw.ucv(est1))
densidad_t2 <- density(est2, kernel = "gauss", window = bw.ucv(est2))
plot(densidad_t2, col = "violet")
lines(densidad_t1, col = "orange")
legend("topright", legend = c("densidad primer estimador varianza", "densidad segundo estimador varianza"), col = c("orange", "violet"), lty = c(1, 1), lwd = c(2, 2))
#Ejercicio e
error1 <- (1/rep) * error1
error1
error2 <- (1/rep) * error2
error2
library(MASS)
log_verosimilitud_gamma <- function(params, datos) {
alpha <- params[1]
lambda <- params[2]
n <- length(datos)
log_verosimilitud <- n * (alpha * log(lambda) - lgamma(alpha)) +
(alpha - 1) * sum(log(datos)) - lambda * sum(datos)
return(log_verosimilitud)  # Retorno sin negativo para maximize
}
derivada_parcial_alpha <- function(alpha, lambda, datos, n) {
return(n * (digamma(alpha) - log(lambda)) + sum(log(datos)))
}
derivada_parcial_lambda <- function(alpha, lambda, datos, n) {
return(-sum(datos) + n * alpha / lambda)
}
newton_raphson <- function(datos, i) {
n <- length(datos)  # Obtener n
alpha_mom <- mean(datos)^2 / var(datos)
lambda_mom <- mean(datos) / var(datos)
alpha <- alpha_mom
lambda <- lambda_mom
for (iter in 1:i) {
d_alpha_val <- derivada_parcial_alpha(alpha, lambda, datos, n)
d_lambda_val <- derivada_parcial_lambda(alpha, lambda, datos, n)
incremento_alpha <- d_alpha_val / optimize(function(x) log_verosimilitud_gamma(c(x, lambda), datos), interval = c(0.001, 100))$objective
incremento_lambda <- d_lambda_val / optimize(function(x) log_verosimilitud_gamma(c(alpha, x), datos), interval = c(0.001, 100))$objective
alpha <- alpha - incremento_alpha
lambda <- lambda - incremento_lambda
}
return(c(alpha, lambda))
}
# Prueba con diferentes tamaños de muestra y repetir 10 veces
set.seed(456)
tamaños_muestra <- c(6, 10, 20, 40, 80, 200)
shape <- 3
rate <- 4
reps <- 5
# Vectores para almacenar los ECM
ECM_alpha_momentos <- c()
ECM_alpha_MV <- c()
ECM_lambda_momentos <- c()
ECM_lambda_MV <- c()
for (n in tamaños_muestra) {
error_cuadratico_medio_alpha_momentos <- 0
error_cuadratico_medio_alpha_MV <- 0
error_cuadratico_medio_lambda_momentos <- 0
error_cuadratico_medio_lambda_MV <- 0
for (k in 1:reps) {
datos <- rgamma(n, shape = shape, scale = 1/rate)
alpha_momentos <- mean(datos)^2 / var(datos)
lambda_momentos <- mean(datos) / var(datos)
estimador_MV <- newton_raphson(datos, i = 10)
error_cuadratico_medio_alpha_momentos <- error_cuadratico_medio_alpha_momentos + ((alpha_momentos - shape)^2)/reps
error_cuadratico_medio_alpha_MV <- error_cuadratico_medio_alpha_MV + ((rate - estimador_MV[1])^2)/reps
error_cuadratico_medio_lambda_momentos <- error_cuadratico_medio_lambda_momentos + ((shape - lambda_momentos)^2)/reps
error_cuadratico_medio_lambda_MV <- error_cuadratico_medio_lambda_MV + ((rate - estimador_MV[2])^2)/reps
}
# Guardar los ECM en los vectores
ECM_alpha_momentos <- c(ECM_alpha_momentos, error_cuadratico_medio_alpha_momentos)
ECM_alpha_MV <- c(ECM_alpha_MV, error_cuadratico_medio_alpha_MV)
ECM_lambda_momentos <- c(ECM_lambda_momentos, error_cuadratico_medio_lambda_momentos)
ECM_lambda_MV <- c(ECM_lambda_MV, error_cuadratico_medio_lambda_MV)
}
# Graficar los ECM
plot(tamaños_muestra, ECM_alpha_momentos, type = "b", col = "blue", xlab = "Tamaño de muestra", ylab = "ECM", main = "ECM para estimador de momentos (alpha)")
points(tamaños_muestra, ECM_alpha_MV, type = "b", col = "red")
points(tamaños_muestra, ECM_lambda_momentos, type = "b", col = "green")
points(tamaños_muestra, ECM_lambda_MV, type = "b", col = "purple")
legend("topright", legend = c("ECM_alpha_momentos", "ECM_alpha_MV", "ECM_lambda_momentos", "ECM_lambda_MV"), col = c("blue", "red", "green", "purple"), pch = c(1, 1, 1, 1))
?digamma
setwd("~/Estadística/Guía2")
library(MASS)
log_verosimilitud_gamma <- function(params, datos) {
alpha <- params[1]
lambda <- params[2]
n <- length(datos)
log_verosimilitud <- n * (alpha * log(lambda) - lgamma(alpha)) +
(alpha - 1) * sum(log(datos)) - lambda * sum(datos)
return(-log_verosimilitud)  # Se retorna el negativo para maximizar
}
derivada_parcial_alpha <- function(alpha, lambda, datos) {
n <- length(datos)
return(n * (digamma(alpha) - log(lambda)) + sum(log(datos)))
}
derivada_parcial_lambda <- function(alpha, lambda, datos) {
return(-sum(datos) + n * alpha / lambda)
}
newton_raphson <- function(datos, i) {
#Arranco con los de momentos como X_0
alpha_mom <- mean(datos)^2 / var(datos)
lambda_mom <- mean(datos) / var(datos)
alpha <- alpha_mom
lambda <- lambda_mom
for (iter in 1:i) {
# Calcular derivadas
d_alpha_val <- derivada_parcial_alpha(alpha, lambda, datos)
d_lambda_val <- derivada_parcial_lambda(alpha, lambda, datos)
# Calcular incremento de parámetros. Lo de optimize me lo sugirió chat-gpt para que queden mejor las divisiones
incremento_alpha <- d_alpha_val / optimize(function(x) -log_verosimilitud_gamma(c(x, lambda), datos), interval = c(0.001, 100))$objective
incremento_lambda <- d_lambda_val / optimize(function(x) -log_verosimilitud_gamma(c(alpha, x), datos), interval = c(0.001, 100))$objective
alpha <- alpha - incremento_alpha
lambda <- lambda - incremento_lambda
}
return(c(alpha, lambda))
}
library(MASS)
log_verosimilitud_gamma <- function(params, datos) {
alpha <- params[1]
lambda <- params[2]
n <- length(datos)
log_verosimilitud <- n * (alpha * log(lambda) - lgamma(alpha)) +
(alpha - 1) * sum(log(datos)) - lambda * sum(datos)
return(-log_verosimilitud)  # Se retorna el negativo para maximizar
}
derivada_parcial_alpha <- function(alpha, lambda, datos) {
n <- length(datos)
return(n * (digamma(alpha) - log(lambda)) + sum(log(datos)))
}
derivada_parcial_lambda <- function(alpha, lambda, datos) {
return(-sum(datos) + n * alpha / lambda)
}
newton_raphson <- function(datos, i) {
#Arranco con los de momentos como X_0
alpha_mom <- mean(datos)^2 / var(datos)
lambda_mom <- mean(datos) / var(datos)
alpha <- alpha_mom
lambda <- lambda_mom
for (iter in 1:i) {
# Calcular derivadas
d_alpha_val <- derivada_parcial_alpha(alpha, lambda, datos)
d_lambda_val <- derivada_parcial_lambda(alpha, lambda, datos)
# Calcular incremento de parámetros. Lo de optimize me lo sugirió chat-gpt para que queden mejor las divisiones
incremento_alpha <- d_alpha_val / optimize(function(x) -log_verosimilitud_gamma(c(x, lambda), datos), interval = c(0.001, 100))$objective
incremento_lambda <- d_lambda_val / optimize(function(x) -log_verosimilitud_gamma(c(alpha, x), datos), interval = c(0.001, 100))$objective
alpha <- alpha - incremento_alpha
lambda <- lambda - incremento_lambda
}
return(c(alpha, lambda))
}
# Pruebo con 1000 datos
set.seed(456)
n <- 1000
shape <- 3
rate <- 0.25
datos_gamma <- rgamma(n, shape = shape, scale = 1/rate)
# Estimar parámetros por Newton-Raphson con 10 iteraciones
estimacion <- newton_raphson(datos_gamma, i = 10)
estimacion
error_estimacion <- c(abs(estimacion[1] - shape), abs(estimacion[2] - rate))
error_estimacion
plot(datos_gamma)
set.seed(2023)
n = 20
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
set.seed(2023)
n = 20
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
set.seed(2023)
n = 20
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
?sd
set.seed(2023)
n = 20
Nrep = 1000
estimador1 <-  c()
estimador2 <- c()
for (i in 1:Nrep) {
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
estimador1 <- c(estimador1, est1)
estimador2 <- c(estimador2, est2)
}
par(mfrow = c(1, 2))
boxplot(estimador1)
boxplot(estimador2)
par(mfrow = c(1, 2))
boxplot(estimador1, col = "orange")
boxplot(estimador2, col = "violet")
par(mfrow = c(1, 2))
boxplot(estimador1, col = "orange", main = "Estimador de la varianza 1")
boxplot(estimador2, col = "violet", main = "Estimador de la varianza 2")
par(mfrow = c(1, 2))
boxplot(estimador1, col = "orange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "violet", main = "Estimador de la varianza T2")
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1)
lines(densidad_est2)
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1)
lines(densidad_est2)
plot(densidad_est1, main = "Estimador no paramétrico de la densidad")
lines(densidad_est2)
plot(densidad_est1,col = "orange", main = "Estimador no paramétrico de la densidad", xlab = "x")
lines(densidad_est2, col = "violet")
par(mfrow = c(1, 2))
boxplot(estimador1, col = "darkorange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "purple", main = "Estimador de la varianza T2")
'Podemos observar que la mediana (linea negra) de las varianzas es más pequeña en el segundo estimador,
lo cual es positivo ya que para que un estimador sea consistente mientras más datos tenga, la varianza
tiene que ser cercana a 0. Para la misma cantidad de datos, en ese aspecto, el segundo estimador es mejor.
Ahora, T2 tiene muchos más outliers que T1, qye tiene muchos más datos dentro del medio'
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x")
lines(densidad_est2, col = "purple")
?plot
?plot()
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 2)
lines(densidad_est2, col = "purple")
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 3)
lines(densidad_est2, col = "purple", lwd = 3)
?plot
error_cuadratico_medio <- function(estimador){
return(var(estimador) + ((estimador - 4)**2))
}
set.seed(2023)
n = 20
Nrep = 1000
estimador1 <-  c()
estimador2 <- c()
error_est_1 <- 0
error_est_2 <- 0
for (i in 1:Nrep) {
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
estimador1 <- c(estimador1, est1)
estimador2 <- c(estimador2, est2)
error_est_1 <-  error_est_1 + error_cuadratico_medio(est1)
error_est_2 <- error_est_2 + error_cuadratico_medio(est2)
}
par(mfrow = c(1, 2))
boxplot(estimador1, col = "darkorange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "purple", main = "Estimador de la varianza T2")
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 3,)
lines(densidad_est2, col = "purple", lwd = 3)
error_est_1 <- 1/Nrep
error_est_1
error_est_2 <- 1/Nrep
error_est_2
set.seed(2023)
n = 20
Nrep = 1000
estimador1 <-  c()
estimador2 <- c()
error_est_1 <- 0
error_est_2 <- 0
for (i in 1:Nrep) {
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
estimador1 <- c(estimador1, est1)
estimador2 <- c(estimador2, est2)
error_est_1 <-  error_est_1 + error_cuadratico_medio(est1)
error_est_2 <- error_est_2 + error_cuadratico_medio(est2)
}
par(mfrow = c(1, 2))
boxplot(estimador1, col = "darkorange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "purple", main = "Estimador de la varianza T2")
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 3,)
lines(densidad_est2, col = "purple", lwd = 3)
error_est_1 <-error_est_1 * 1/Nrep
error_est_1
error_est_2 <- error_est_2 * 1/Nrep
error_est_2
error_est_1 <-error_est_1 * (1/Nrep)
error_est_1
error_est_2 <- error_est_2 * (1/Nrep)
error_est_2
class(error_est_1)
error
1/Nrep * error_est_1
(1/1000) * error_est_1
error_cuadratico_medio <- function(estimador){
return(var(estimador) + ((estimador - 4)^2))
}
set.seed(2023)
n = 20
Nrep = 1000
estimador1 <-  c()
estimador2 <- c()
error_est_1 <- 0
error_est_2 <- 0
for (i in 1:Nrep) {
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
estimador1 <- c(estimador1, est1)
estimador2 <- c(estimador2, est2)
error_est_1 <-  error_est_1 + error_cuadratico_medio(est1)
error_est_2 <- error_est_2 + error_cuadratico_medio(est2)
}
par(mfrow = c(1, 2))
boxplot(estimador1, col = "darkorange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "purple", main = "Estimador de la varianza T2")
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 3,)
lines(densidad_est2, col = "purple", lwd = 3)
error_est_1 <-error_est_1 * (1/Nrep)
error_est_1
error_est_2 <- error_est_2 * (1/Nrep)
error_est_2
error_est_1
var(estimador)
error_cuadratico_medio <- function(estimador){
return(var(estimador) + ((estimador - 4)^2))
}
View(error_cuadratico_medio)
error_cuadratico_medio <- function(estimador){
return((sd(estimador)^2) + ((estimador - 4)^2))
}
set.seed(2023)
n = 20
Nrep = 1000
estimador1 <-  c()
estimador2 <- c()
error_est_1 <- 0
error_est_2 <- 0
for (i in 1:Nrep) {
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
estimador1 <- c(estimador1, est1)
estimador2 <- c(estimador2, est2)
error_est_1 <-  error_est_1 + error_cuadratico_medio(est1)
error_est_2 <- error_est_2 + error_cuadratico_medio(est2)
}
par(mfrow = c(1, 2))
boxplot(estimador1, col = "darkorange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "purple", main = "Estimador de la varianza T2")
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 3,)
lines(densidad_est2, col = "purple", lwd = 3)
error_est_1 <-error_est_1 * (1/Nrep)
error_est_1
error_est_2 <- error_est_2 * (1/Nrep)
error_est_2
error_cuadratico_medio <- function(estimador){
abs_var <- abs(estimador - 4)
return(var(estimador) + abs_var^2)
}
set.seed(2023)
n = 20
Nrep = 1000
estimador1 <-  c()
estimador2 <- c()
error_est_1 <- 0
error_est_2 <- 0
for (i in 1:Nrep) {
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
estimador1 <- c(estimador1, est1)
estimador2 <- c(estimador2, est2)
error_est_1 <-  error_est_1 + error_cuadratico_medio(est1)
error_est_2 <- error_est_2 + error_cuadratico_medio(est2)
}
par(mfrow = c(1, 2))
boxplot(estimador1, col = "darkorange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "purple", main = "Estimador de la varianza T2")
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 3,)
lines(densidad_est2, col = "purple", lwd = 3)
error_est_1 <-error_est_1 * (1/Nrep)
error_est_1
error_est_2 <- error_est_2 * (1/Nrep)
error_est_2
error_cuadratico_medio <- function(estimador){
if (is.nan(estimador)) {
estimador <- 0  # o cualquier otro valor que desees asignar
}
return(var(estimador) + ((estimador - 4)**2))
}
set.seed(2023)
n = 20
Nrep = 1000
estimador1 <-  c()
estimador2 <- c()
error_est_1 <- 0
error_est_2 <- 0
for (i in 1:Nrep) {
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
estimador1 <- c(estimador1, est1)
estimador2 <- c(estimador2, est2)
error_est_1 <-  error_est_1 + error_cuadratico_medio(est1)
error_est_2 <- error_est_2 + error_cuadratico_medio(est2)
}
par(mfrow = c(1, 2))
boxplot(estimador1, col = "darkorange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "purple", main = "Estimador de la varianza T2")
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 3,)
lines(densidad_est2, col = "purple", lwd = 3)
error_est_1 <-error_est_1 * (1/Nrep)
error_est_1
error_est_2 <- error_est_2 * (1/Nrep)
error_est_2
error_cuadratico_medio <- function(estimador){
return((estimador - 4)**2)
}
set.seed(2023)
n = 20
Nrep = 1000
estimador1 <-  c()
estimador2 <- c()
error_est_1 <- 0
error_est_2 <- 0
for (i in 1:Nrep) {
muestra <-  rexp(n, 0.5)
est1 <- mean(muestra)^2
est2 <- sd(muestra)^2
estimador1 <- c(estimador1, est1)
estimador2 <- c(estimador2, est2)
error_est_1 <-  error_est_1 + error_cuadratico_medio(est1)
error_est_2 <- error_est_2 + error_cuadratico_medio(est2)
}
par(mfrow = c(1, 2))
boxplot(estimador1, col = "darkorange", main = "Estimador de la varianza T1")
boxplot(estimador2, col = "purple", main = "Estimador de la varianza T2")
par(mfrow = c(1,1))
densidad_est1 <- density(estimador1, kernel = "gauss", window = bw.ucv)
densidad_est2 <- density(estimador2, kernel = "gauss", window = bw.ucv)
plot(densidad_est1,col = "darkorange", main = "Estimador no paramétrico de la densidad", xlab = "x", lwd = 3,)
lines(densidad_est2, col = "purple", lwd = 3)
error_est_1 <-error_est_1 * (1/Nrep)
error_est_1
error_est_2 <- error_est_2 * (1/Nrep)
error_est_2
